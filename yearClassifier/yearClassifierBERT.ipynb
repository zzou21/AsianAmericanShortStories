{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program trains a BERT model to identify whether the inputted story is published before or after 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import BertForTokenClassification, TrainingArguments, Trainer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section builds a dataset where the variable \"dataset\" is a list of dictionaries in this format: [{\"story\": storyContent, \"year\": publicationYear, \"label\": 1 for after 2014 and 0 for before 2014}]\n",
    "\n",
    "storyDataJsonPath = \"publicationYearStory.json\"\n",
    "with open(storyDataJsonPath, \"r\") as file:\n",
    "    storyData = json.load(file)\n",
    "dataset = [{\"story\": story, \"year\": int(year)} for year, story in storyData.items()]\n",
    "for story in dataset:\n",
    "    story[\"label\"] = 1 if story[\"year\"] >2004 else 0\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def tokenizeStories(stories):\n",
    "    return tokenizer(stories[\"story\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "tokenizedStories = [tokenizeStories(storyItem) for storyItem in dataset]\n",
    "#print(tokenizedStories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(tokenizedStories, label):\n",
    "    return{\n",
    "        \"input_ids\": torch.tensor(tokenizedStories[\"input_ids\"]),\n",
    "        \"attentionMask\": torch.tensor(tokenizedStories[\"attention_mask\"]),\n",
    "        \"label\": torch.tensor(label)\n",
    "    }\n",
    "formattedData = [formatData(tokenizedStories[i], dataset[i][\"label\"]) for i in range(len(tokenizedStories))]\n",
    "#print(formattedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [terms[\"label\"] for terms in dataset]\n",
    "trainingData, validationData = train_test_split(formattedData, test_size=0.2, stratify=labels, random_state=2000)\n",
    "#print(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a class for PyTorch (could use another code if one wants to use pyarrow):\n",
    "class StoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "trainingDataset = StoryDataset(trainingData)\n",
    "validationDataset = StoryDataset(validationData)\n",
    "#print(trainingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingArgument = TrainingArguments(output_dir=\"./trainingResult\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainingArgument,\n",
    "    train_dataset=trainingDataset,\n",
    "    eval_dataset=validationDataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b21df0d7904982bde8a68fb39d5d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 248.9354, 'train_samples_per_second': 0.121, 'train_steps_per_second': 0.024, 'train_loss': 0.6219557921091715, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc041e1898374595821c52379a6d3d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./modelTrained/tokenizer_config.json',\n",
       " './modelTrained/special_tokens_map.json',\n",
       " './modelTrained/vocab.txt',\n",
       " './modelTrained/added_tokens.json',\n",
       " './modelTrained/tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "model.save_pretrained('./modelTrained/')\n",
    "tokenizer.save_pretrained(\"./modelTrained/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training ends above. The code below processes the user input data.\n",
    "modelPath = \"modelTrained\"\n",
    "newModel = BertForSequenceClassification.from_pretrained(modelPath)\n",
    "newTokenizer = AutoTokenizer.from_pretrained(modelPath)\n",
    "newModel.eval()\n",
    "\n",
    "def predictInputYear(story, model, tokenizer, threshold=0.5):\n",
    "    inputStory = tokenizer(story, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
    "    operatingDevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # cuda -> gpu\n",
    "    model.to(operatingDevice)\n",
    "    inputStory = {key: value.to(model.device) for key, value in inputStory.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputStory)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # getting probabilities\n",
    "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "    \n",
    "    # Use 0.5 threshold for binary classification\n",
    "    label = 1 if probabilities[1] > threshold else 0\n",
    "    if label == 1:\n",
    "        return {\"sentiment\": \"After 2014\", \"probability\": probabilities[1]}\n",
    "    else:\n",
    "        return {\"sentiment\": \"Before 2014\", \"probability\": probabilities[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'After 2004', 'probability': 0.5053929}\n"
     ]
    }
   ],
   "source": [
    "storyInput = \"This is a story set in Los Angeles. The name of the story is called The Big Sleep. It is unsure who wrote The Big Sleep or whe. All that everyone cares about is the freeway sign that says 'Los Angeles, 19 miles.'\"\n",
    "resultPrediction = predictInputYear(storyInput, model, tokenizer)\n",
    "print(\"Prediction results\", resultPrediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
